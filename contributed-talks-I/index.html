<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Contributed talks on Tuesday, 12/09 | IICCSSS  </title>
    <meta name="author" content="IICCSSS  ">
    <meta name="description" content="International Interdisciplinary Computational Cognitive Science Summer School
">
    <meta name="keywords" content="cognitive-science, summer-school">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%A0&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://www.iiccsss.org/contributed-talks-I/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">IICCSSS </span></a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">IICCSSS</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/venue/">venue</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/speakers/">speakers</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/program/">program</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/registration/">registration</a>
              </li>
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">about us</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/organisers/">organisers</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/philosophy/">philosophy</a>
                </div>
              </li>
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="https://kirchner-jan.github.io/IICCSSS" rel="external nofollow noopener" target="_blank">IICCSSS 2022</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/2021/">IICCSSS 2021</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/2019/">IICCSSS 2019</a>
                </div>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Contributed talks on Tuesday, 12/09</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <h3 id="computational-modeling-of-cognition-room-hs01">Computational modeling of cognition (Room HS01)</h3>

<table>
<colgroup>
<col width="15%">
<col width="85%">
</colgroup>
<thead>
<tr class="header">
<th>Time</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>13:30–13:50</td>
<td>
<em>Revan Rangotis</em> <br>

<strong>Drift-diffusion modelling reveals distinct decision processes for 3D and global motion stimuli in humans and macaques</strong> <br>

Neurophysiology localised perceptual decision signals for binocular 3D depth and motion stimuli to visual area V5/MT. Drift diffusion modelling (DDM) is widely used to investigate the underlying decision-making processes by simulating decisions as noisy evidence-accumulation which terminates once a threshold is crossed. Two key questions remain unexplored: 1. To what extent are modelled decision processes affected by the visual stimulus (here 3D depth vs. motion) and by the effector for the response (hand vs. saccades)? 2. Are the modelling parameters comparable between monkeys and humans? To answer these questions, we tested 2 male monkeys (Macaca mulatta) and 20 humans on different stimulus/effector combinations in a 2-alternative forced-choice task (2AFC). Stimuli were a 3D structure-from-motion cylinder or a random dot kinematogram (RDK), requiring perceptual decisions about binocular depth or direction of motion, respectively. Effectors comprised hand and saccadic eye movements. Linear discriminant analysis (LDA) revealed a strong separation by stimulus type but not for the effector for the human data (p&lt;0.001, ROC analysis). Nearly identical clustering was observed for the monkey data when it was projected onto the same space with almost complete overlap. We conclude that DDM reveals distinct brain processes for perceptual decisions about visual motion and binocular 3D stimuli in humans and macaques, although perceptual signals for both have been localised to the same brain area. We found no distinction between hand and eye movement responses in either species.
</td>
</tr>
<tr>
<td>13:50–14:10</td>
<td>
<em>Surabhi S Nath</em> <br>

<strong>Inside the grid, yet outside the box: Computational investigations of human creativity using pixel patterns</strong> <br>

Creativity is an important, yet elusive, human characteristic. Despite strides in understanding creativity as a cognitive ability, there is a paucity of computational studies associated with it. Our work aims to fill this gap with a computational investigation of the mechanisms underlying little-c creative artistic work, from a reward learning perspective. We define tractably constrained experimental settings involving binary 5x5 pixel patterns. We develop a taxonomy with two types of creativity – static and dynamic, crossed with two modes of creativity – evaluation and production, resulting in four experimental conditions for investigation. We outline various possible underlying computational mechanisms such as (1) an immediate value function for static creativity, (2) a long-run value function for dynamic creativity, (3) the history-dependent nature of evaluation and (4) a search process guiding the production. We design a series of behavioural experiments based on our taxonomy and propose directions for data analyses. Through this we aim to enrich the computational understanding of product and process creativity.
</td>
</tr>
<tr>
<td>14:10–14:30</td>
<td>
<em>Yuki Tsukamura</em> <br>

<strong>Cognitive modeling of the latent scope bias in causal explanations</strong> <br>

Latent scope bias refers to the tendency to prefer explanations that do not predict unobservable events over those that do in causal explanations. The occurrence of latent scope bias is believed to be due to an underestimation of the occurrence probability of unobservable events and Bayesian probability calculations using it. However, it remains unclear whether it is based on Bayesian probability calculations. Therefore, we employed subjective probability response data and compared this process with alternative models through Bayesian modeling. As a result, a cognitive model based on “subjective utility” was favored over Bayesian probability calculations, suggesting that the process of evaluating explanations leading to the latent scope bias is not based on Bayesian probability calculations. <br>
Furthermore, while latent scope bias was observed in the aggregated data from all participants, it was not necessarily a large effect, and it was shown that it did not occur in a certain number of the participants when looked at individually. In other words, a certain number of normative respondents answered values corresponding to the normative solution with relatively small variance. From these findings, it is also suggested that the latent scope bias may appear to arise in the entire group due to a certain number of people with bias.
</td>
</tr>
<tr>
<td>14:30–14:50</td>
<td>
<em>Ryutaro Mori</em> <br>

<strong>How real-time interaction aids collaboration under the temptations to free ride</strong><br>

Understanding how human groups collaborate successfully, even when individuals may be tempted to free ride, is a fundamental question in the social sciences. While conventional models such as game theory often distill socially dependent situations into simplified “staged settings” in which agents choose actions only at fixed timings, real-world collaborations are typically marked by real-time interactions in which decisions are made instantaneously and communicated immediately. Our research posits that such real-time interactions facilitate collaboration by naturally creating a sequence of cooperative actions and reactions. Specifically, when decision timings are sequential rather than simultaneous, each decision becomes a response to prior ones, mitigating much of the social unpredictability and aiding coordination. Moreover, if agents themselves can decide when to act, the earlier/precedent decisions could lean more towards cooperation than if they were random; cooperative agents might decide early to encourage reciprocation, while competitive agents might delay revealing their intentions. We formulate these ideas using a classic prisoner’s dilemma game and experimentally verify several key behavioral regularities. In the talk, I would particularly love to discuss how computational modeling can be employed to decipher real-time strategic interactions.
</td>
</tr>
</tbody>
</table>
<p><br></p>

<h3 id="neuroscience-room-sr003">Neuroscience (Room SR003)</h3>

<table>
<colgroup>
<col width="15%">
<col width="85%">
</colgroup>
<thead>
<tr class="header">
<th>Time</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>13:30–13:50</td>
<td>
<em>Viktor Bublitz</em><br>

<strong>Monitoring nociception in the frontal EEG</strong> <br>

Monitoring pain and nociception in critical care patients who cannot self-report presents a substantial challenge. Clinical signs frequently lack both sensitivity and specificity, and existing technical methodologies come with inherent limitations. Accurate predictions of nociception could optimize the administration of analgesia ahead of procedures like endotracheal suctioning. In my doctoral research, I explored strategies to quantify nociception and anticipate reactions to painful interventions in intensive care settings. We particularly examined electroencephalogram (EEG) correlates that either precede or occur simultaneously with behavioral responses to noxious stimuli, such as endotracheal suctioning. Our results showed an elevation in power within the 2-5Hz band that both anticipated and matched these responses, coupled with a decrease in the alpha-band power during these events. Such patterns could be associated with the processing of noxious stimuli and might pave the way for refining and individualizing analgesia in patients unable to articulate their pain. Notably, other power bands and ratios did precede the responses in our study, but these could be attributed more to the concurrent sedation level and arousal than to nociception. Deciphering these intertwined effects is the motivation behind the research that I am currently conceptualizing for subsequent investigations.
</td>
</tr>
<tr>
<td>13:50–14:10</td>
<td>
<em>Jonas Elpelt</em> <br>

<strong>The interplay of synaptic remodeling, forgetting and creativity</strong> <br>

Why do we forget? The fascinating phenomenon of forgetting is often associated with pathologies such as dementia, but forgetting can have crucial positive effects for behavioral flexibility and can enforce more creative abilities. Recently, it has been shown that forgetting involves biological mechanisms that actively and selectively ‘erase’ memory information and can lead to changes on different organizational levels (synapses, neurons, networks, behavior). In a joint German-Israeli project we want to study the change of representations under continuous synaptic reconfiguration in vitro, in vivo and in silico models. By investigating spontaneous dynamics in network configurations we want to explore the possibility that spontaneous changes in synaptic connection might drive forgetting. For this purpose we use the behavioral readout of forgetting and adaptive learning to construct a theoretical framework to link forgetting and intrinsic synaptic dynamics. Finally we want to establish a possible relationship of forgetting, increased synaptic plasticity and creativity in both biological and artificial neural networks.
</td>
</tr>
<tr>
<td>14:10–14:30</td>
<td>
<em>Ralf Krüger</em> <br>

<strong>Comparison of preprocessing of EEG hyperscanning data with different automated algorithms</strong> <br>

In the context of naturalistic, out-of-lab brain imaging situations, the data quality is often not optimal. I am currently comparing several preprocessing algorithms (Artificial Subspace Reconstruction, global and local Autoreject and Automated ICA) on their ability to clean data obtained in an neurofeedback art exhibit. Two participants were shown a sculpture while simultaneously measuring inter-brain synchronisation with an 8-channel EEG system as part of the exhibit Brain Palace in the STATE Studio Berlin. I will present the results of this experiment as well as standard preprocessing methods on the power spectrum density of the subjects and several connectivity metrics. Since the connectivity metrics are very sensitive to changes in the frequency domain of the signals, care has to be taken that within subject pairs the signal is processed in similar ways, which needs to be accounted for in artifact removal. I used the Hyperscanning Pipeline for Python HyPyP to perform most of the analysis, but implemented some additional functionality to visualize the intermediate results and measure connectivity metrics not yet specified in the pipeline. I will also present a signal-to-noise ratio and its limitations for determining signal quality in this context.
</td>
</tr>
<tr>
<td>14:30–14:50</td>
<td>
<em>Guillaume Pourcel</em> <br>

<strong>Skill homeostasis: Toward a model of ultra-robust behavior</strong> <br>

In this talk, I’ll present my current research directions in modeling the impressive phenomenon of ultra-robust behavior in humans, focusing on two intriguing cases: sensory substitution and inverted vision. Sensory substitution demonstrates the brain’s rapid adaptation to distorted sensory inputs, such as retranslating visual information into tactile sensations through an array of vibrators. Inverted vision studies are concerned with our abilities to adapt to the disruption of our visual processing by presenting the world upside-down. Both cases showcase remarkable resilience in the face of diverse perturbations. <br>

Conventionally, explanations for robust behavior have rested upon the premise of a meta-learning framework, wherein evolution optimizes learning rules capable of coping with the variability of environments experienced during phylogeny. We propose an alternative hypothesis that suggests that the brain employs a homeostatic mechanism to regulate skills when faced with unprecedented disturbances. Drawing inspiration from computational neuroscience and population dynamics, we view the brain as a nonlinear dynamical system with distinct skill-related patterns encoded in the activity of neural populations. <br>

Central to our model is the identification of skill-specific linear subspaces, acting as references for regulation. When significant perturbations occur, the brain seeks equilibrium by readjusting its internal dynamics. This novel perspective not only addresses robustness in a volatile environment but also unveils a mechanism for the brain to restore stability amidst unforeseen challenges.
</td>
</tr>
</tbody>
</table>


          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 IICCSSS. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Front page photo from <a href="https://unsplash.com/photos/biClFIGKHqI" target="_blank" rel="external nofollow noopener">Unsplash</a>.
Last updated: September 07, 2023.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
